---
title: "Final Exam"
author: "Gabriel Rivera Alvarez"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries Used
```{r}
# Libraries to be used
library(tidyverse)
library(car)
library(olsrr)
library(lindia)
library(MASS)
library(corrplot)
library(alr3)
library(table1)
library(sjPlot)
```

## Data Reading
```{r}
# Load dataset
data <- read.csv("/Users/gabrielrivera/Documents/Maestria/Courses/4- Summer 2022/STA6235/Final Exam/JHS_final.csv")

# Extract variables of interest and put them as a tibble
dataset <- tibble(HbA1c=data$HbA1c, age=data$age, alc=data$alc, HTN = data$HTN, sex=data$sex, totchol=data$totchol, waist=data$waist)

# Remove rows with NA
dataset <- drop_na(dataset)
```

## 1. The group includes hypertension researchers, so let’s describe the data with respect to hypertension status (HTN). Create a table of descriptives of the variables listed above, split by hypertension status (yes/no).
```{r}
table1 <- table1(~ HbA1c + age + alc + sex + totchol + waist | HTN, data = dataset,caption="HTN")
table1=as_tibble(table1)
names(table1) <- c(" ","Normotensive (HTN: No)","Hypertensive (HTN: Yes)","HTN: Overall")
table1[1,2:4] <- t(c('N=1069 (87.84%)','N=148 (12.16%)','N=1217'))
table1[,1:3]
```

## 2. Model HbA1c as a function of the other variables listed above.

### a. What is the resulting regression model?
```{r}
m1 <- lm(HbA1c ~ age + alc + HTN + sex + totchol + waist, data=dataset)
s1 <- summary(m1)
lin_coeff <- s1$coefficients
```

\[ \hat{HbA1c} = `r lin_coeff[1]` + `r lin_coeff[2]`*age + `r lin_coeff[3]`*alc + `r lin_coeff[4]`*HTN + `r lin_coeff[5]`*sex + `r lin_coeff[6]`*totchol + `r lin_coeff[7]`*waist\]

### b. Create the following table with the $\hat{\beta_i}$ and corresponding 95% CI’s rounded to 2 decimal places and the p-values rounded to 3 decimal places. Note that if the p-value rounds to 0, you should state that it is < 0.001.
```{r}
table2 <- tab_model(m1,
                    string.ci="95% CI",
                    string.p="p-Value")
table2
```

### c. Which, if any, are significant predictors of HbA1c?

- Age, and waist are significant predictors because they have a p-Value of less than 0.05. Alcohol use (alc), hypertension (HTN), sex, and total cholesterol (totchol) are not significant predictor because they have a p-Value greater than 0.05.

### d. Provide a brief interpretation for each predictor.

- Age: For every increase of 1 year in age, we expect for hemoglobin to increase by 0.017% after adjusting for alcohol use, hypertension, sex, total cholesterol, and waist circumference.

- Alcohol use: For a person that has drank alcohol in the past 12 months, we expect for hemoglobin to decrease by 0.020% after adjusting for age, hypertension, sex, total cholesterol, and waist circumference.

- Hypertension: For a person with a hypertension status, we expect for hemoglobin to increase by 0.14% after adjusting for age, alcohol use, sex, total cholesterol, and waist circumference.

- Sex: For a male person in sex, we expect for hemoglobin to increase by 0.015% after adjusting for age, alcohol use, hypertension, total cholesterol, and waist circumference.

- Total cholesterol: For every increase of total cholesterol and fasting time in total cholesterol, we expect for hemoglobin to increase by 0.000053% after adjusting for age, alcohol use, hypertension, sex, and waist circumference.

- Waist circumference: For every increase of 1 cm in waist circumference, we expect for hemoglobin to increase by 0.014% after adjusting for age, alcohol use, hypertension, sex, and total cholesterol.

## 3. Model HbA1c as a function of the other variables listed above as well as all two-way interactions involving hypertension status.

### a. What is the resulting regression model?
```{r}
m2 <- lm(HbA1c ~ age + alc + HTN + sex + totchol + waist 
         + age:HTN + alc:HTN + sex:HTN + HTN:totchol + HTN:waist, data=dataset)
s2 <- summary(m2)
lin_coeff <- s2$coefficients
```

\[\hat{HbA1c} = `r lin_coeff[1]` + `r lin_coeff[2]`*age + `r lin_coeff[3]`*alc + `r lin_coeff[4]`*HTN + `r lin_coeff[5]`*sex + `r lin_coeff[6]`*totchol + `r lin_coeff[7]`*waist + `r lin_coeff[8]`*age:HTN + `r lin_coeff[9]`*alc:HTN + `r lin_coeff[10]`*HTN:sex + `r lin_coeff[11]`*HTN:totchol + `r lin_coeff[12]`*HTN:waist\]

### b. Using a single hypothesis test, show that we cannot drop all of the interaction terms at the same time.
```{r}
full <- m2
reduced <- lm(HbA1c ~ age + alc + HTN + sex + totchol + waist, data = dataset)
an_results <- anova(reduced,full)
```

**Hypotheses**

  - $H_0: \ \beta_{\text{age:HTN}} = \beta_{\text{alc:HTN}} = \beta_{\text{HTN:sex}} = \beta_{\text{HTN:totchol}} = \beta_{\text{HTN:waist}} = 0$
  - $H_1:$ at least one $\beta_i \ne 0$

**Test Statistics**

  - $F_0 = `r round(an_results$F[2],3)`$
  - $p$-Value $= `r round(an_results$"Pr(>F)"[2],3)`$

**Rejection Region**

  - Reject $H_0$ if $p$-Value $< \alpha$; $\alpha = 0.05$

**Conclusion and Interpretation**

  - Reject $H_0$. There is sufficient evidence to suggest that at least one $\beta_i$ is not equal to zero. Therefore, they cannot be dropped all at the same time.

### c. Using multiple individual hypothesis tests, determine which interaction term(s) can be dropped from the model.

#### Is the interaction between age and hypertension status a significant predictor?

**Hypotheses**

  - $H_0: \ \beta_{\text{age:HTN}} = 0$
  - $H_1: \ \beta_{\text{age:HTN}} \ne 0$

**Test Statistics**

  - $t_0 = `r round(abs(s2$coefficients[8,3]),3)`$
  - $p$-Value $=$ $`r if_else(s2$coefficients[8,4] < 0.001, as.character('<0.001'), as.character(round(s2$coefficients[8,4],3)))`$
  
**Rejection Region**

  - Reject $H_0$ if $p$-Value $< \alpha$; $\alpha = 0.05$

**Conclusion and Interpretation**

  - FTR $H_0$. There is not sufficient evidence to suggest that the interaction between age and hypertension status is a significant predictor of hemoglobin. This interaction term can be dropped.

#### Is the interaction between alcohol use and hypertension status a significant predictor?

**Hypotheses**

  - $H_0: \ \beta_{\text{alc:HTN}} = 0$
  - $H_1: \ \beta_{\text{alc:HTN}} \ne 0$

**Test Statistics**

  - $t_0 = `r round(abs(s2$coefficients[9,3]),3)`$
  - $p$-Value $=$ $`r if_else(s2$coefficients[9,4] < 0.001, as.character('<0.001'), as.character(round(s2$coefficients[9,4],3)))`$
  
**Rejection Region**

  - Reject $H_0$ if $p$-Value $< \alpha$; $\alpha = 0.05$

**Conclusion and Interpretation**

  - FTR $H_0$. There is not sufficient evidence to suggest that the interaction between alcohol use and hypertension status is a significant predictor of hemoglobin. This interaction term can be dropped.

#### Is the interaction between hypertension status and sex a significant predictor?

**Hypotheses**

  - $H_0: \ \beta_{\text{HTN:sex}} = 0$
  - $H_1: \ \beta_{\text{HTN:sex}} \ne 0$

**Test Statistics**

  - $t_0 = `r round(abs(s2$coefficients[10,3]),3)`$
  - $p$-Value $=$ $`r if_else(s2$coefficients[10,4] < 0.001, as.character('<0.001'), as.character(round(s2$coefficients[10,4],3)))`$
  
**Rejection Region**

  - Reject $H_0$ if $p$-Value $< \alpha$; $\alpha = 0.05$

**Conclusion and Interpretation**

  - Reject $H_0$. There is sufficient evidence to suggest that the interaction between hypertension status and sex is a significant predictor of hemoglobin. This interaction term cannot be dropped.

#### Is the interaction between hypertension status and total cholesterol a significant predictor?

**Hypotheses**

  - $H_0: \ \beta_{\text{HTN:totchol}} = 0$
  - $H_1: \ \beta_{\text{HTN:totchol}} \ne 0$

**Test Statistics**

  - $t_0 = `r round(abs(s2$coefficients[11,3]),3)`$
  - $p$-Value $=$ $`r if_else(s2$coefficients[11,4] < 0.001, as.character('<0.001'), as.character(round(s2$coefficients[11,4],3)))`$
  
**Rejection Region**

  - Reject $H_0$ if $p$-Value $< \alpha$; $\alpha = 0.05$

**Conclusion and Interpretation**

  - Reject $H_0$. There is sufficient evidence to suggest that the interaction between hypertension status and total cholesterol is a significant predictor of hemoglobin. This interaction term cannot be dropped.

#### Is the interaction between hypertension status and waist circumference a significant predictor?

**Hypotheses**

  - $H_0: \ \beta_{\text{HTN:waist}} = 0$
  - $H_1: \ \beta_{\text{HTN:waist}} \ne 0$

**Test Statistics**

  - $t_0 = `r round(abs(s2$coefficients[12,3]),3)`$
  - $p$-Value $=$ $`r if_else(s2$coefficients[12,4] < 0.001, as.character('<0.001'), as.character(round(s2$coefficients[12,4],3)))`$
  
**Rejection Region**

  - Reject $H_0$ if $p$-Value $< \alpha$; $\alpha = 0.05$

**Conclusion and Interpretation**

  - FTR $H_0$. There is not sufficient evidence to suggest that the interaction between hypertension status and waist circumference is a significant predictor of hemoglobin. This interaction term can be dropped.

## 4. Model HbA1c as a function of the other variables listed above and the significant two-way interactions involving hypertension status, as identified in Question 3c.

### a. What is the resulting regression model?
```{r}
m3 <- lm(HbA1c ~ age + alc + HTN + sex + totchol + waist + HTN:sex + HTN:totchol, data=dataset)
s3 <- summary(m3)
lin_coeff <- s3$coefficients
```

\[ \hat{HbA1c} = `r lin_coeff[1]` + `r lin_coeff[2]`*age + `r lin_coeff[3]`*alc + `r lin_coeff[4]`*HTN + `r lin_coeff[5]`*sex + `r lin_coeff[6]`*totchol + `r lin_coeff[7]`*waist + `r lin_coeff[8]`*HTN:sex + `r lin_coeff[9]`*HTN:totchol\]

### b. Create visualizations to help explain the interactions to your collaborators. Note: there should be at least one visualization for each interaction term in your model.
```{r}
# Plot of interaction between hypertension status and total cholesterol
plot_model(m3, type='pred', terms=c('totchol','HTN'))

# Plot of interaction between hypertension status and sex
plot_model(m3, type='pred', terms=c('sex','HTN'))
```

### c. Write a summary paragraph – for your collaborators – explaining the interaction terms, based on what you’ve observed in the graphs created for Question 4b.

- We end up keeping two interaction terms. They are the interaction between hypertension status and total cholesterol, and the interaction between hypertension status and sex. The first graph is the resulting graph of the interaction between hypertension status and total cholesterol. In this graph we can observe that for people that have no hypertension status (red line), the hemoglobin will slightly decrease as total cholesterol increases. On the other hand, for people that have a hypertension status (blue line), the hemoglobin will increase as total cholesterol increases. The second graph is the resulting graph of the interaction between hypertension status and sex. In this graph we can observe that males with hypertension (blue) had lower hemoglobin when compared to males with no hypertension (red). On the other hand, females with hypertension (blue) had higher hemoglobin when compared to females with no hypertension (red).

## 5. Using the model from Question 4,

### a. Create a flag variable for outliers. Use the table() function to count the number of outliers. How many potential outliers exist in the dataset?
```{r}
# Studentized Deleted Residuals
dataset$Stud_Residuals <- studres(m3)

# Residuals Flag Variable
dataset$Residuals_Flag <- if_else(abs(dataset$Stud_Residuals) >= 3, 1 , 0)

# Count number of potential outliers
outlier_count <- table(dataset$Residuals_Flag)
```

- There are `r outlier_count[2]` potential outliers.

### b. Check for influence/leverage points using the graph for Cook’s distance. How many potential influence/leverage points exist?
```{r}
# Influence Measures 
influence_measures <- as_tibble(influence.measures(m3)$infmat)

# Add Cook's Distance to Dataset
dataset$Cook_Dist <- influence_measures$cook.d

# Cook's Distance Flag Variable
dataset$Cook_Dist_Flag <- if_else(abs(dataset$Cook_Dist) >= 4/nrow(dataset), 1 , 0)

# Count number of potential influence/leverage points
influ_lev_count <- table(dataset$Cook_Dist_Flag)

# Cook's Distance Plot
gg_cooksd(m2) + theme_bw()
```

There are `r influ_lev_count[2]` potential influence/leverage points.

### c. Conduct a sensitivity analysis and exclude the outliers and/or the influence/leverage points.

#### i. What is the resulting model?
```{r}
# Remove outliers and influence/leverage points
dataset2 <- dataset %>% filter(Residuals_Flag == 0)
dataset2 <- dataset %>% filter(Cook_Dist_Flag == 0)

m4 <- lm(HbA1c ~ age + alc + HTN + sex + totchol + waist + HTN:sex + HTN:totchol, data=dataset2)
s4 <- summary(m4)
lin_coeff <- s4$coefficients
```

\[ \hat{HbA1c} = `r lin_coeff[1]` + `r lin_coeff[2]`*age + `r lin_coeff[3]`*alc + `r lin_coeff[4]`*HTN + `r lin_coeff[5]`*sex + `r lin_coeff[6]`*totchol + `r lin_coeff[7]`*waist + `r lin_coeff[8]`*HTN:sex + `r lin_coeff[9]`*HTN:totchol\]

#### ii. Complete the following table with βi and corresponding 95% CI’s rounded to 2 decimal places and the p-values rounded to 3 decimal places. Note that if the p-value rounds to 0, you should state that it is < 0.001.
```{r}
table3 <- tab_model(m3,m4,
                    dv.labels=c("HbA1c with Ofending Data","HbA1c withot Ofending Data"),
                    string.ci="95% CI",
                    string.p="p-Value")
table3
```
#### iii. Describe the differences between the models.

- Comparing the p-Values of the model with the offending data against the model without offending data we can draw similar conclusions. In both cases we need to keep age, waist, and the interaction between hypertension and total cholesterol because they have p-Values of less than 0.05. Similarly, in both cases we can drop the predictors of alcohol use, hypertension status, sex and total cholesterol because all of them have p-Values greater than 0.05. The only difference is that the model with offending data needs to keep the interaction between hypertension and sex because the p_value is less than 0.05 while it can be dropped in the model without offending data because the p-Value is greater than 0.05. The other main difference is that $R^2_{adj}$ for the model without offending data is able to explain around 16.6% of the hemoglobin variability while the model with the offending data can only explain around 12.1%.

#### iv. Do you feel that the models are different enough that we should investigate the offending data? Explain your response to the question.

- My advice would be to further analyze the offending data to make sure the report is as accurate as possible. Also, I would communicate to the collaborators that there's only one term in the model that has differing results when analyzing model with offending data versus model without offending data. I would ask if they would like a deeper analysis or what has been provided is sufficient to meet their needs.

## 6. Using the model from question 4,

### a. Construct the correlation matrix for the predictors.
```{r}
# Convert categorical variables from character to numeric
dataset$alc <- if_else(dataset$alc == "Yes", as.integer(1),as.integer(0))
dataset$HTN <- if_else(dataset$HTN == "Yes", as.integer(1),as.integer(0))
dataset$sex <- if_else(dataset$sex == "Male",as.integer(1),as.integer(0))

corrM <- cor(dataset[,2:7])
corrplot(corrM, method="number")
```

### b. Are any correlations such that you suspect multicollinearity?

- No. Based on the correlation matrix I do not suspect that there will be multicollinearity effects between the predictors.

### c. Formally check for multicollinearity. Does it exist with this predictor set? Justify your answer.
```{r}
vif(m1)
```

- Formally looking at multicollinearity effects for the predictor set, there is none. The Variance Inflation Factor (VIF) for each of the predictors is very close to 1 so I do not expect to have estimation issues due to correlation between predictors.

## 7. Using the model from question 4,

### a. Use the almost sas() function to graphically assess the assumptions. Include the resulting graph.
```{r}
almost_sas <- function(aov.results){
  aov_residuals <- residuals(aov.results)
  par(mfrow=c(2,2))
  plot(aov.results, which=1)
  hist(aov_residuals)
  plot(aov.results, which=2)
  plot(density(aov_residuals))
}
almost_sas(m3)
```

### b. What is your assessment? Are any of the assumptions broken? Justify your answer.

- Doing a regression assessment it can be observed that the residuals follow a normal distribution with 0 mean and $\sigma^2$ variance. From The histogram it can be observed that the data is skewed. From Q-Q plot it can be observed that the points at the end of the line are the ones skewing the data.

### c. Perform the lack of fit test.
```{r}
m3_LOF <- pureErrorAnova(m3)
m3_LOF
```
### d. Based on your answers to the other pieces of this question, do you feel that this is a valid analysis? Justify your answers.

- Yes. This is a valid analysis. The data is skewed and outliers and influential points are the reason of that but that is what you would expect in real life data. Not everything has to fit into textbook world. You can still drive some conclusions from the analysis and do a deep sensitivity analysis to understand well how the offending data is behaving and affecting the the overall results. From the Lack of Fit it can be observed that predictors alcohol use, sex, and total cholesterol have a p-Value greater than 0.05 so FTR that they have no lack of fit. On the other hand, with predictors age, hypertension status, waist and interaction terms HTN:sex and HTN:totchol one reject and says there is enough evidence to say they have lack of fit. This is based on final model of question 4 that has all the data and adding to the sensitivity analysis can shed more light into this.






